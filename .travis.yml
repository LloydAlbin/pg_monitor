language: bash
services: docker
sudo: required

# blocklist
#branches:
#  except:
#  - experimental

# safelist
#branches:
#  only:
#  - master

#addons:
#  apt:
#    packages:
#      - libcurl4-openssl-dev
#      - libelf-dev
#      - libdw-dev
#      - cmake

#before_script: |
#  wget https://github.com/SimonKagstrom/kcov/archive/master.tar.gz &&
#  tar xzf master.tar.gz &&
#  cd kcov-master &&
#  mkdir build &&
#  cd build &&
#  cmake .. &&
#  make &&
#  sudo make install &&
#  cd ../.. &&
#  rm -rf kcov-master &&
#  mkdir -p coverage

# https://blog.travis-ci.com/2017-10-26-running-kubernetes-on-travis-ci-with-minikube
env:
  global:
    - CHANGE_MINIKUBE_NONE_USER=true
    - MINIKUBE_WANTUPDATENOTIFICATION=false
    - MINIKUBE_WANTREPORTERRORPROMPT=false
    - MINIKUBE_HOME=$HOME
    - CHANGE_MINIKUBE_NONE_USER=true
    - KUBECONFIG=$HOME/.kube/config

before_script:
  # Download kubectl, which is a requirement for using minikube.
  - curl -Lo kubectl https://storage.googleapis.com/kubernetes-release/release/v1.16.0/bin/linux/amd64/kubectl && chmod +x kubectl && sudo mv kubectl /usr/local/bin/
  # Download minikube.
  - curl -Lo minikube https://storage.googleapis.com/minikube/releases/v1.4.0/minikube-linux-amd64 && chmod +x minikube && sudo mv minikube /usr/local/bin/
  - mkdir -p $HOME/.kube $HOME/.minikube
  - touch $KUBECONFIG
  - sudo minikube start --vm-driver=none --kubernetes-version=v1.16.0
  - "sudo chown -R travis: /home/travis/.minikube/"

script:
  # Following is just to demo that the kubernetes cluster works.
  - kubectl cluster-info
  # Verify kube-addon-manager.
  # kube-addon-manager is responsible for managing other kubernetes components, such as kube-dns, dashboard, storage-provisioner..
  - JSONPATH='{range .items[*]}{@.metadata.name}:{range @.status.conditions[*]}{@.type}={@.status};{end}{end}'; until kubectl -n kube-system get pods -lcomponent=kube-addon-manager -o jsonpath="$JSONPATH" 2>&1 | grep -q "Ready=True"; do sleep 1;echo "waiting for kube-addon-manager to be available"; kubectl get pods --all-namespaces; done
  # Wait for kube-dns to be ready.
  - JSONPATH='{range .items[*]}{@.metadata.name}:{range @.status.conditions[*]}{@.type}={@.status};{end}{end}'; until kubectl -n kube-system get pods -lk8s-app=kube-dns -o jsonpath="$JSONPATH" 2>&1 | grep -q "Ready=True"; do sleep 1;echo "waiting for kube-dns to be available"; kubectl get pods --all-namespaces; done
  # Create example Redis deployment on Kubernetes.
  - kubectl run travis-example --image=redis --labels="app=travis-example"
  # Make sure created pod is scheduled and running.
  - JSONPATH='{range .items[*]}{@.metadata.name}:{range @.status.conditions[*]}{@.type}={@.status};{end}{end}'; until kubectl -n default get pods -lapp=travis-example -o jsonpath="$JSONPATH" 2>&1 | grep -q "Ready=True"; do sleep 1;echo "waiting for travis-example deployment to be available"; kubectl get pods -n default; done
  #- ls -l
  # Using the default build paramaters for a fresh build
  - ~/build/LloydAlbin/pg_monitor/timescaledb/custom/build_timescaledb.sh -v -v -v -V --add pgtap
  # Testing the Upgrade Path and add pgtap for unit testing pg_monitor later on
  #- ~/build/LloydAlbin/pg_monitor/timescaledb/custom/build_timescaledb.sh -v -v -v --location=~ --add pgtap
  # Testing Removing of both Postgres and TimescaleDB repositories
  #- ~/build/LloydAlbin/pg_monitor/timescaledb/custom/build_timescaledb.sh -v -v -v --clean
  # Using the optional arguments for a fresh build
  #- ~/build/LloydAlbin/pg_monitor/timescaledb/custom/build_timescaledb.sh -v -v -v --org=dreg.scharp.org --ts_name=scharp-timescaledb --pg_name=scharp-postgres
  # Using the optional arguments for the Upgrade Path
  #- ~/build/LloydAlbin/pg_monitor/timescaledb/custom/build_timescaledb.sh -v -v -v --org=dreg.scharp.org --pg_name=scharp-postgres --postgres
  # Using the optional arguments for the Upgrade Path
  #- ~/build/LloydAlbin/pg_monitor/timescaledb/custom/build_timescaledb.sh -v -v -v --org=dreg.scharp.org --ts_name=scharp-timescaledb --timescaledb
  # Testing Removing of TimescaleDB repository and then rebuilding just the TimescaleDB
  #- ~/build/LloydAlbin/pg_monitor/timescaledb/custom/build_timescaledb.sh -v -v -v --clean timescaledb --timescaledb --override_exit
  # Testing Removing of Postgres repository
  #- ~/build/LloydAlbin/pg_monitor/timescaledb/custom/build_timescaledb.sh -v -v -v --clean postgres
  #- pwd
  - kubectl apply -f ~/build/LloydAlbin/pg_monitor/timescaledb/kubernetes/pg-monitor-timescaledb-service.yaml
  - kubectl apply -f ~/build/LloydAlbin/pg_monitor/timescaledb/kubernetes/pg-monitor-timescaledb-deploy.yaml
  - kubectl apply -f ~/build/LloydAlbin/pg_monitor/grafana/kubernetes/pg-monitor-grafana-service.yaml
  - kubectl apply -f ~/build/LloydAlbin/pg_monitor/grafana/kubernetes/pg-monitor-grafana-deployment.yaml

after_script:
  - docker images
  #- bash <(curl -s https://codecov.io/bash)>
  - kubectl get all
  
# vim:set et ts=2 sw=2:
